import logging  # ğŸ“Œ Importamos logging para depuraciÃ³n
from flask import Flask, request, jsonify  # ğŸŒ Flask para crear el servicio web
from flask_cors import CORS  # ğŸ”„ Permite habilitar CORS y evitar problemas con peticiones externas
from transformers import MarianMTModel, MarianTokenizer  # ğŸ¤– Cargar el modelo de traducciÃ³n
import torch  # ğŸ”¥ PyTorch para manejar el modelo de Hugging Face

# ğŸ“Œ Configurar logging para depuraciÃ³n y monitoreo del servicio
logging.basicConfig(level=logging.DEBUG)

# ğŸš€ Crear la aplicaciÃ³n Flask
app = Flask(__name__)
CORS(app)  # ğŸ”„ Habilita CORS para permitir peticiones desde cualquier origen

### ğŸ“Œ MODELO DE TRADUCCIÃ“N (InglÃ©s â¡ EspaÃ±ol)
model_translation_name = "Helsinki-NLP/opus-mt-en-es"
logging.info("ğŸ”„ Cargando el modelo de traducciÃ³n...")  # ğŸ› ï¸ Mensaje de inicio de carga

# ğŸ¤– Cargamos el modelo de traducciÃ³n desde Hugging Face
model_translation = MarianMTModel.from_pretrained(model_translation_name)
tokenizer_translation = MarianTokenizer.from_pretrained(model_translation_name)

logging.info("âœ… Modelo de traducciÃ³n cargado correctamente.")  # âœ”ï¸ ConfirmaciÃ³n de carga exitosa


### ğŸŒ Endpoint de traducciÃ³n ğŸ“Œ
@app.route("/translate", methods=["POST", "OPTIONS"])  # ğŸš€ Endpoint accesible en /translate
def translate():
    """ğŸ“¢ Recibe un texto en inglÃ©s y lo traduce al espaÃ±ol"""
    
    logging.info(f"ğŸ“¨ Solicitud recibida en /translate con mÃ©todo {request.method}")

    # ğŸŒ Manejo de preflight request de CORS (cuando el frontend verifica permisos antes de enviar datos)
    if request.method == "OPTIONS":
        response = jsonify({"message": "âœ… CORS preflight request successful"})  # ğŸŸ¢ Respuesta exitosa
        response.headers.add("Access-Control-Allow-Origin", "*")  # ğŸŒ Permitir todas las solicitudes
        response.headers.add("Access-Control-Allow-Methods", "POST, OPTIONS")  # ğŸ“Œ MÃ©todos permitidos
        response.headers.add("Access-Control-Allow-Headers", "Content-Type")  # ğŸ“œ Cabecera permitida
        return response, 200  # âœ… Respuesta HTTP 200 OK

    try:
        # ğŸ“¥ Obtener los datos enviados en la solicitud (esperamos JSON)
        data = request.get_json()
        
        # ğŸš¨ Verificar si el JSON es vÃ¡lido y contiene el campo "text"
        if not data or "text" not in data or not data["text"].strip():
            logging.warning("âš ï¸ Texto vacÃ­o en la solicitud de traducciÃ³n")  # âš ï¸ Advertencia en logs
            return jsonify({"error": "No text provided"}), 400  # â›” Devolver error 400 (Bad Request)

        logging.info(f"ğŸ“œ Texto recibido para traducciÃ³n: {data['text']}")  # ğŸ“œ Log del texto de entrada

        # ğŸ”  Tokenizar el texto antes de pasarlo al modelo
        inputs = tokenizer_translation(data["text"], return_tensors="pt", truncation=True, padding=True)

        # ğŸ”„ Generar la traducciÃ³n sin necesidad de calcular gradientes
        with torch.no_grad():
            translated_tokens = model_translation.generate(**inputs)

        # ğŸ“ Decodificar el resultado de la traducciÃ³n
        translated_text = tokenizer_translation.decode(translated_tokens[0], skip_special_tokens=True)

        logging.info(f"âœ… Texto traducido: {translated_text}")  # âœ”ï¸ ConfirmaciÃ³n de traducciÃ³n exitosa

        # ğŸ“¤ Devolver la traducciÃ³n en formato JSON
        return jsonify({"translated_text": translated_text})

    except Exception as e:
        # ğŸš¨ Capturar cualquier error y loguearlo
        logging.error(f"âŒ Error en la traducciÃ³n: {str(e)}", exc_info=True)
        return jsonify({"error": str(e)}), 500  # â›” Error 500 (Internal Server Error)


### ğŸš€ Iniciar el servidor Flask
if __name__ == "__main__":
    logging.info("ğŸš€ Servidor Flask iniciÃ¡ndose en http://127.0.0.1:5555")  # ğŸ”¥ Mensaje de inicio
    app.run(host="0.0.0.0", port=5555, debug=True)  # ğŸŒ Iniciar servidor en localhost:5555 con depuraciÃ³n activada